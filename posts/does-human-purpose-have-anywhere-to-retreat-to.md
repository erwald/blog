---
layout: layouts/post.njk
title: Does Human Purpose Have Anywhere to Retreat to?
date: 2022-05-21
tags: post
---

# Does Human Purpose Have Anywhere to Retreat to?

![img]({{ '/img/zeus.jpeg' | url }})

As gods once lived in streams and forests and then on mountain tops and deep down below the earth, then withdrawn to the blue heavens and, at last, as we mapped the heavens too, altogether outside the material world, so purpose is on the retreat as science marches on, telling us first that we humans, like all animals, are mere products of evolution, that love is an [adaptation executor](https://www.lesswrong.com/tag/adaptation-executors), that the gods are not real, and finally -- what?

Having a sense of purpose involves having a goal and structuring one's life around that goal (King and Hicks 2021) (cf. [Networks of Meaning]({{ '/posts/networks-of-meaning/)' | url }}). There are different sorts of goals. Some are more subject-oriented and others more world-oriented. For example, one person may have as a goal to learn how to play the flute. It can be intrinsically satisfying to learn a new skill and to play an instrument well, and no one else can learn how to play the flute _for that person_ -- that is something only they can do for themselves; nor does it matter that other people can play the flute better. But another person may have as a goal to provide for their family, or to make a great work of art, or to help the disadvantaged, or to advance a field of science or philosophy. Those are things that others can do, too; nobody with a goal like that has a monopoly on their goal.

What will happen to those goals in the future? There is a real possibility that we create [artificial superintelligence](https://forum.effectivealtruism.org/topics/superintelligence) in our lifetimes. Whether or not such a superintelligence will have [values aligned with ours](https://forum.effectivealtruism.org/topics/ai-alignment) is up in the air, but let's suppose for the moment that it will do as we want. That would mean there's an agent out there that is better than the best of us at providing economically, creating art, helping the disadvantaged, making scientific and philosophical progress and just about anything else that we may want to do. Then the entire second class of goals -- world-oriented goals -- will be meaningless to pursue, as the superintelligence can achieve them for us, far more easily, quickly and efficiently than we could ever hope to.

If true, that means many humans will have to radically rethink their purpose in life. Maybe we have to do that even before a superintelligence arrives. Does it make sense to labour away at a great novel if you expect a machine to write, fifty years from now, a thousand far greater novels in mere seconds? Bostrom puts it better:

> Suppose you had to build a new subway line, and it was this grand trans-generational enterprise that humanity was engaged in, and everybody had a little role. So you have a little shovel. But if you know that a giant bulldozer will arrive on the scene tomorrow, then does it really make sense to spend your time today digging the big hole with your shovel? Maybe there is something else you could do with your time. Maybe you could put up a signpost for the great shovel, so it will start digging in the right place. (Khatchadourian 2015)

## References

<style>.csl-entry{text-indent: -2em; margin-left: 2em;}</style><div class="csl-bib-body">
  <div class="csl-entry">Khatchadourian, Raffi. 2015. “The Doomsday Invention.” <i>The New Yorker</i> 23.</div>
  <div class="csl-entry">King, Laura A., and Joshua A. Hicks. 2021. “The Science of Meaning in Life.” <i>Annual Review of Psychology</i> 72 (1): 561--84. https://doi.org/10.1146/annurev-psych-072420-122921</div>
</div>
